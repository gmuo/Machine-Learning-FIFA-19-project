---
title: "MDP I - Base de datos de FIFA 19"
subtitle: "Grupo 14"
author: "Pablo Bolta Ballester, Cristina Portilla Alique, Evgeny Grachev, Guillermo Ferrando Muñoz"
date: "`r Sys.Date()`"
output:
  word_document:
    toc: yes
    number_sections: yes
    toc_depth: '3'
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    toc: yes
    number_sections: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: yes
---

```{r setup, warning=FALSE,include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(fastDummies)
library(FactoMineR)
library(factoextra)
library(tidyr)
library(dplyr)
library(magrittr)
library(VIM)
library(pcaMethods)
library(missMDA)
library(knitr)
library(ggplot2)
library(ggpubr)
library(corrplot)
library(naniar)
library(cluster)
library(FactoMineR)
library(factoextra)
library(NbClust)
library(clValid)
library(fastcluster)
library(knitr)
library(naniar)
library(ropls)
library(pls)
library(caret)
```


# Introducción

Esta base de datos proviene del repositorio de datos Kaggle y contiene información de todos los jugadores pertenecientes al videojuego FIFA 19, un videojuego de fútbol que se puede jugar en cualquier dispositivo electrónico. En este trabajo, estudiaremos los futbolistas y sus variables con dos objetivos principales: encontrar agrupamientos verosímiles/útiles/legítimos de dichos jugadores y predecir el valor (precio) o cualquier otra variable que resuma la calidad de un jugador de fútbol. Los agrupamientos serían de ayuda en caso de que, por ejemplo, un jugador haya resultado lesionado, poder encontrar sustitutos. Respecto al otro objetivo, si se quiere formar un nuevo equipo de fútbol, se podría estimar su calidad en general.


## Descripción de las variables

En un principio, usaremos 56 variables que serán relevantes para nuestro estudio, y 17918 observaciones que se corresponden a los diferentes jugadores de fútbol del videojuego.

- **IDENTIFICADOR: **
  - **Name:** nombre del jugador (lo usaremos para identificar a los jugadores).


- **NUMÉRICAS: **
  - **Height:** altura (cm).
  - **Weight:** peso (kg).
  - **Crossing:** precisión en los centros.
  - **Finishing:** capacidad de convertir (meter) un gol. 
  - **HeadingAccuracy:** precisión y facilidad al golpear de cabeza.
  - **ShortPassing:** pases cortos.
  - **Volleys:** remates acrobáticos con los pies.
  - **Dribbling:** superar rivales regateando. 
  - **Curve:** capacidad de que la pelota cambie de dirección durante la trayectoria. 
  - **FKAccuracy:** precisión en los tiros libres. 
  - **LongPassing:** pases largos. 
  - **BallControl:** control de balón.
  - **Acceleration:** velocidad en las primeras zancadas.
  - **SprintSpeed:** velocidad máxima en carrera.
  - **Agility:** agilidad con la pelota. Giros y movimientos rápidos y precisos. 
  - **Reactions:** velocidad de movimientos con el balón. 
  - **Balance:** equilibrio aguantando el contacto de otros jugadores. 
  - **ShotPower:** potencia imprimida al golpear la pelota. 
  - **Jumping:** capacidad de salto para imponerse en balones aéreos.
  - **Stamina:** fortaleza física.
  - **Strength:** fuerza ante el contacto.
  - **LongShots:** disparos desde fuera del área. 
  - **Aggression:** fuerza con la que va a por la pelota. 
  - **Interceptions:** posicionamiento en defensa para cortar centros y pases.
  - **Positioning:** desmarques o colocación para recibir el balón. 
  - **Vision:** capacidad de ver huecos, anticipar desmarques y aprovecharlos.
  - **Penalties:** acierto en los penaltis. 
  - **Composure:** compostura, le afecta menos la presión del defensor. 
  - **Marking:** capacidad de contener a un atacante.
  - **StandingTackle:** facilidad para quitar la pelota sin hacer una entrada agresiva.
  - **SlidingTackle:** facilidad para quitar la pelota haciendo entradas agresivas.
  - **GKDiving:** estirada, más posibilidad de interceptar tiros colocados. 
  - **GKHandling:** habilidad para detener y retener la pelota con claridad y facilidad.
  - **GKKicking:** precisión y alcance de un saque de portería.
  - **GKPositioning:** posicionamiento de un portero.
  - **GKReflexes:** reflejos ante disparos a bocajarro.

**NOTA:** todas las variables numéricas excepto edad, valor, sueldo, altura y peso, son puntuaciones que se les otorgan a los jugadores con valores posibles entre 0-99.
**NOTA 2:** las variables GKDiving, GKHandling, GKKicking, CKPositioning y GKReflexes son habilidades que corresponden únicamente a los jugadores con posición portero (POR).


- **ORDINALES: **
  - **International.Reputation:** reputación a nivel internacional.
  - **Weak.Foot:** nivel de su pie débil.
  - **Skill.Moves:** puntuación en cuanto a skills (habilidades).
**NOTA:** son variables ordinales codificadas del 1-5, con nota 1 si tienen mala puntuación y nota 5 si tienen buena puntuación en cada variable.


- **CATEGÓRICAS: **
  - **Nationality:** nacionalidad del jugador.
  - **Club:** equipo del jugador. 
  - **Preferred.Foot:** pie dominante del jugador, codificada como binaria: **Preferred.Foot_Left** (zurdo), **Preferred.Foot_Right** (diestro).
  - **Position:** posición del jugador. Demasiados valores posibles. Las ocho categorías en las que hemos decidido agrupar a los jugadores son las que hemos considerado más comunes en el fútbol actual, considerando centrales, delanteros, extremos, laterales, mediocentros, mediocentros defensivos, mediocentros ofensivos y porteros. Hemos tomado la semejanza entre la posición asignada en el fifa del jugador y una de las elegidas como criterio, por ejemplo hemos asignado a los carrileros como laterales, o a los segundos delanteros como delanteros, ya que es la posición a la que más se asemejan. Codificada como *dummy* (**Position.CEN**, **Position.DEL**, **Position.EXT**, **Position.LAT**, **Position.MED**, **Position.MEDDEF**, **Position.MEDOF**, **Position.POR**)


# Pre-procesado de los datos
```{r importar datos, include=FALSE}
datos = read.csv("FIFA.csv", encoding = 'UTF-8', na.strings=c("","na"))
#Los datos faltantes estaban escritos como espacios en blanco, por lo que los sustituimos por NA para tratarlos con mayor facilidad
```

```{r borrar variables, include=FALSE}

fifa = datos[,-c(1,2,3,5,7,11,14,19:21,23:26,29:54,89)]
fifa_paralelo = datos[,-c(1,2,5,7,11,14,19:21,23:26,29:54,89)]
```


Hemos eliminado algunas variables que no hemos considerado útiles para el análisis, como enlaces a fotos o número de la camiseta. Para el tratamiento de datos faltantes, realizamos una primera exploración de los datos. Obtenemos el porcentaje de datos faltantes existente en cada columna y observamos una baja cantidad de datos faltantes, en concreto hay 241 jugadores con valor faltante en la variable Club y 60 jugadores con valor faltante en la variable Posición. Como vemos en los porcentajes, el 0,26% de los jugadores de la base de datos no tienen valores sobre las variables de habilidades. Al tratarse de un grupo tan reducido y de jugadores poco importantes, decidimos eliminarlos directamente. 


```{r variables faltantes, include=FALSE}
#sum(is.na(fifa$Club))
#sum(is.na(fifa$Position))
#sum(is.na(fifa$Height))

#aggr(fifa, plot = TRUE, borders = NA, combined = TRUE, numbers = FALSE, bars = TRUE, only.miss = TRUE)
kable(t(apply(fifa, 2, function(x) (sum(is.na(x))/nrow(fifa)*100))))

fifa <- na.omit(fifa)  #eliminar los faltantes
```


## Limpieza y asignación de los tipos de variables adecuados

Hay variables que no están en su clase correspondiente, y algunas que hay que modificar para facilitar su tratamiento. 
Eliminamos símbolo € de las variables Wage y Value, las transformamos a tipo numérico. Por otro lado, también transformamos el peso expresándolo en kilos en vez de libras y la altura a centímetros en vez de pies. Pasamos ambas a numérico. 

La variable Preferred.Foot la convertimos a dicotómica y la variable Position se pasa a dummy (Preferred.Foot sería dummy también), ya que tiene 27 valores diferentes y nos interesa convertirlos en ocho (portero, lateral, central, medio, medio ofensivo, medio defensivo, extremo y delantero), agrupándolos por las categorías más importantes para facilitar la interpretación de las variables.

```{r transformacion de precio y valor, include=FALSE}

#Eliminamos el simbolo de € de la variable value
fifa$Value = gsub("^\\€", "", fifa$Value)

#Eliminamos el simbolo de € de la variable wage
fifa$Wage = gsub("^\\€", "", fifa$Wage)

#Transformamos el texto en número de acuerdo a si es M€, K€ o €.
numeric_value = function(char){
      num = as.numeric(substring(char, 1, nchar(char)-1))
      k = substring(char,nchar(char),nchar(char))
      mult = 1
      if(k=='M'){mult = 1000000}
      if(k=='K'){mult = 1000}
      num*mult
}
fifa$Value = sapply(fifa$Value, numeric_value)
fifa$Wage = sapply(fifa$Wage, numeric_value)

fifa[which(is.na(fifa$Value)),]$Value = 0

#La variable de la altura del jugador está medida en pies más pulgadas. La transformamos a valor numérico expresado en cms.

fifa$Height = as.numeric(gsub("\'\\w+$", "", fifa$Height))*30.48 +
      as.numeric(gsub("^\\w+'", "", fifa$Height))*2.54

#La variable Weight representa el peso del jugador en libras. La transformamos a valor numérico expresado en kgs.

fifa$Weight = as.numeric(gsub("lbs$", "", fifa$Weight))*0.453592



#La variable Preferred.Foot se pasa a tipo binario.

library(fastDummies)
fifa = dummy_cols(fifa, select_columns = 'Preferred.Foot', remove_selected_columns = TRUE)


## Position

for (i in 1:nrow(fifa)){
  if(fifa$Position[i] %in% c('CF', 'ST', 'RF', 'LF', 'LS', 'RS')){fifa$Position[i]='DEL'}
  if(fifa$Position[i] %in% c('RW', 'LW')){fifa$Position[i]='EXT'}
  if(fifa$Position[i] %in% c('LM', 'CM', 'LCM', 'RM', 'RCM')){fifa$Position[i]='MED'}
  if(fifa$Position[i] %in% c('LAM', 'CAM', 'RAM')){fifa$Position[i]='MEDOF'}
  if(fifa$Position[i] %in% c('LDM', 'CDM', 'RDM')){fifa$Position[i]='MEDDEF'}
  if(fifa$Position[i] %in% c('LCB', 'CB', 'RCB')){fifa$Position[i]='CEN'}
  if(fifa$Position[i] %in% c('LWB', 'LB', 'RB', 'RWB')){fifa$Position[i]='LAT'}
  if(fifa$Position[i] %in% c('GK')){fifa$Position[i]='POR'}
}


fifa = dummy_cols(fifa, select_columns = 'Position', remove_selected_columns = FALSE)

#table(fifa$Position)
```


```{r, include=FALSE}
descFifa = data.frame("variable" = colnames(fifa),
                      "tipo" = c("numerical", "categorical",
                                 rep("numerical", 2), "categorical", 
                                 rep("numerical", 5), "categorical",
                                 rep("numerical", 46)), stringsAsFactors = FALSE)
rownames(descFifa) = descFifa$variable
```


# Análisis exploratorio

Hemos realizado un conciso análisis exploratorio de nuestras variables para familiarizarnos con ellas, para verlo en su totalidad, consultar el **Anexo 0**. Ahí estudiamos las distribuciones de cada variable para encontrar posibles datos anómalos y para decidir si será necesario estandarizar todas las variables numéricas de cara a la implementación del PCA más adelante.

Tras el análisis, decidimos centrar y escalar todas nuestras variables numéricas mediante varianza unitaria. A continuación, podemos observar un gráfico de boxplots con todas ellas.

```{r terceros boxplots, echo=FALSE, fig.width=18, fig.height=7}
fifa_numericas = fifa[,setdiff(colnames(fifa), c("Nationality", "Club", "Position", "Preferred.Foot_Right", "Preferred.Foot_Left"))]

fifa_numericas <- scale(fifa_numericas, center = T, scale = T) 
par(mar = c(9,4,2,2))
boxplot(fifa_numericas, las = 2)

```

Cabe mencionar que las variables Value y Wage tienen una gran cantidad de valores fuertemente anómalos, además de haber otras variables como International.Reputation con valores atípicos. Esto nos lleva a la conclusión de que hay que estar atentos a ellas por si tenemos que considerarlas como auxiliares al modelo. Lo veremos más adelante en el primer método aplicado: PCA.


# Primer método - PCA
## Objetivo

Escogemos realizar PCA porque la mayoría de nuestras variables son numéricas, y son las que más se enfocan en nuestro estudio. Con este estudio trataremos de encontrar, en caso de que las haya, relaciones entre las distintas variables consideradas, lo que a su vez derivará en encontrar relaciones entre las observaciones. 


## Implementación del método
### Elección del número de componentes

Realizamos un PCA con todas nuestras variables numéricas tipificadas, incluyendo a las categóricas como auxiliares en el modelo. Primero, elegiremos el número de componentes que queremos para explicar nuestros datos.

```{r inicio PCA, warning=FALSE, echo=FALSE, fig.height=5, fig.width=6}
res.pca = PCA(fifa, scale.unit = TRUE, graph = FALSE, ncp = 10, 
              quali.sup = which(descFifa$tipo == "categorical"))
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca, addlabels = TRUE) +
  geom_hline(yintercept=VPmedio, linetype=2, color="red")
```

Consultando el scree plot, con 6 componentes principales explicaríamos el `r round(res.pca$eig[6,3],2)` de la variabilidad de nuestros datos. Por la alta cantidad de datos anómalos que tenemos, raíz del sospechoso comportamiento de variables como Value y Wage que hemos detectado en el análisis exploratorio anterior, y por la posible presencia de sesgo en las variables de habilidades de los jugadores, parece una cantidad razonable de inercia explicada si escogemos más componentes podríamos estar explicando ruido, o por lo menos más aún del que podrían estar explicando con 6.

Decimos que las variables de habilidades pueden estar sesgadas ya que sus valores están en una escala de 0 a 100, pero al parecer no se basan en un cálculo matemático objetivo.

Para ayudarnos a confirmar el número de componentes principales que nos conviene, recurriremos a la validación cruzada para obtener los estadísticos $R^2$ y $Q^2$: El primer estadístico mide la bondad de ajuste del modelo, a medida que obtengamos más variables, esperaremos que $R^2$ crezca, pero usar únicamente este estadístico no es una buena idea por lo que comentábamos antes sobre el ruido. Con el segundo estadístico obtendremos una visualización de cuál es el rango efectivo de nuestros datos, en otras palabras, $Q^2$ estima la bondad de predicción del modelo.


```{r,warning = FALSE, echo=FALSE, message=FALSE}
#obtenemos Q2
pcIr <- pca(fifa_numericas, nPcs=4)
q2 <- as.vector(Q2(pcIr, fifa_numericas, fold = 2))*100

#obtenemos R2
res.pca = PCA(fifa_numericas, ncp=12, graph = FALSE)
r2 = as.vector(res.pca$eig[1:12,"cumulative percentage of variance"])

#plot
matplot(cbind(r2, q2), type = "l", lty = 1, col = c("blue", "red"))
lines(c(6,6), c(0,105), type = "l", col="gray")
legend(x = "topleft",legend=c("R2", "Q2"), text.col= c("blue", "red"))
```

A la vista del gráfico anterior, podemos observar que $Q^2$ llega a un máximo con 6 componentes, a partir de ahí, las predicciones serán peores. Por tanto, parece que usar un número de 6 componentes principales sí es una buena elección, así que concluimos en usar esa cantidad.

```{r número de componentes, warning=FALSE, echo=FALSE}
res.pca = PCA(fifa, scale.unit = TRUE, graph = FALSE, ncp = 6, 
              quali.sup = which(descFifa$tipo == "categorical"))
#eig.val <- get_eigenvalue(res.pca)
```


### Validación del modelo PCA
#### Detección de anómalos con T2-Hotelling

Como siempre, antes de sacar conclusiones de nuestro modelo PCA, primero tenemos que validarlo. Comenzamos buscando outliers extremos con un gráfico de valores de $T^2$-Hotelling. Las líneas discontinuas se corresponden con los límites de confianza del 95% y 99%, respectivamente en naranja y rojo. Siempre y cuando la cantidad no sea excesiva, **utilizaremos como criterio de aceptación como falsas alarmas que los valores estén por debajo de tres veces el límite de confianza del 99%**, ya que queremos mantener toda la información posible.

```{r T2, echo=FALSE}
#{r T2, fig.width=5, fig.height=5}

K = 6
misScores = res.pca$ind$coord[,1:K]
miT2 = colSums(t(misScores**2) / eig.val[1:K]) # max(miT2) # printeamos el valor máximo
I = nrow(fifa)
F95 = K*(I**2 - 1)/(I*(I - K)) * qf(0.95, K, I-K)
F99 = K*(I**2 - 1)/(I*(I - K)) * qf(0.99, K, I-K)
plot(1:length(miT2), miT2, type = "l", xlab = "Jugadores de FIFA", ylab = "T2", main = "Distancia de Mahalanobis al centro")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)
alarma95 = which(miT2 > F95)
alarma99 = which(miT2 > F99)
#dim(as.matrix(which(miT2 > F99)))
#334/17918

T2_eliminar <- which(miT2 > 3*F99)
#fifa <- fifa[-T2_eliminar,]

```

Viendo el gráfico, podemos observar que hay ciertos jugadores con un valor de T2-Hotelling muy por encima de la línea roja, algunos de estos jugadores son ni más ni menos que Lionel Messi, Cristiano Ronaldo o Neymar. Si comprobamos el porcentaje de jugadores que supera cada límite, es mayor al que se esperaría para ser considerados falsas alarmas: por encima del límite de confianza de 95% tenemos `r dim(as.matrix(which(miT2 > F95)))[1]` observaciones y por encima del límite de 99% tenemos `r dim(as.matrix(which(miT2 > F99)))[1]` observaciones, que respectivamente son el `r round(nrow(as.matrix(which(miT2 > F95)))/17918, 3)`% y el `r round(nrow(as.matrix(which(miT2 > F99)))/17918, 3)`%.


#### Detección de atípicos con SCR

Comprobamos ahora los valores de la suma de cuadrados residual. Para el tratamiento de las alarmas, utilizaremos el mismo criterio que antes en $T^2$-Hotelling.

```{r SCR, echo=FALSE}
#{r SCR, fig.width=5, fig.height=5}

misLoadings = sweep(res.pca$var$coord, 2, sqrt(res.pca$eig[1:K,1]), FUN="/") # para calcular loadings 
fifa_numericas2 <- scale(fifa[,descFifa$tipo == "numerical"], center = T, scale = T) 
#X = as.matrix(fifa_numericas2)
#X[is.na(X)] = 0
myE = fifa_numericas2 - misScores %*% t(misLoadings) 
mySCR = rowSums(myE^2)  
mySCR[is.na(mySCR)] = 0 #hacemos esto para que no de NA
plot(1:length(mySCR), mySCR, type = "l", main = "Distancia al modelo", 
     ylab = "SCR", xlab = "Jugadores de FIFA")
g = var(mySCR)/(2*mean(mySCR))
h = (2*mean(mySCR)^2)/var(mySCR)
chi2lim95 = g*qchisq(0.95, df = h)
chi2lim99 = g*qchisq(0.99, df = h)
abline(h = chi2lim95, col = "orange", lty = 2)
abline(h = chi2lim99, col = "red3", lty = 2)

SCR_eliminar <- which(mySCR > 3*chi2lim99) 
#fifa <- fifa[-SCR_eliminar,]
```

Al haber una serie de valores muy encima de la línea roja, nos encontramos en una situación similar a la de T2-Hotelling. Se diferencia en que el porcentaje de valores que supera los límites está dentro de los permitido: `r round(nrow(as.matrix(which(mySCR > chi2lim95)))/17918, 3)`% (línea naranja), `r round(nrow(as.matrix(which(mySCR > chi2lim99)))/17918, 3)`% (línea roja). Algunos de estos outliers moderados coinciden con algunos de los outliers severos mencionados antes.


#### Contribuciones T2-Hotelling y SCR al modelo 

Los dos gráficos superiores nos han mostrado que esos jugadores tan anómalos y/o atípicos son jugadores muy reconocidos mundialmente, es más Cristiano Ronaldo y Neymar salen en las portadas de FIFA 19. Es lógico que aquellas personas que compren el videojuego quieran conseguir a estos jugadores y formar un equipo con ellos, por lo que no nos interesa deshacernos de estos jugadores tan admirados. En lugar de ir eliminando los valores anómalos y reajustar modelos, estudiaremos las contribuciones de cada variable a la $T^2$-Hotelling y a la SCR de estos outliers.

Lionel Messi tiene el valor más grande de $T^2$-Hotelling y de SCR (es la línea más alta de los gráficos anteriores), aprovecharemos esta coincidencia y haremos sus gráficos de contribución. De esta manera, identificaremos aquellas variables que influyen en mayor medida a generar estas anomalías.

```{r,fig.width=20, fig.height=7, echo=FALSE}
##### Para T2-Hotelling
ContriT2 <- function(datos, modelo, row_name, K, nombres_jugadores){
  #cat("Observación introducida: \n", (t(datos[row_name,])))
  val_propios <- modelo$eig[1:K,1]
  vec_propios <- t(sweep(modelo$var$coord, 2, sqrt(res.pca$eig[1:K,1]), FUN="/"))
  
  u<-mean(datos[row_name,])
  
  scores <- modelo$ind$coord
  col_names <- colnames(datos)
  contrib <- c(rep(0,length(col_names)))
  
  for(i in seq_along(col_names)){
    for(a in 1:length(val_propios)){
      contrib[i] <- contrib[i]+(vec_propios[a,i]*(datos[row_name,i])*(scores[row_name,a])/val_propios[a]) # parece que este es el más parecido
      #contrib[i] <- contrib[i]+abs(vec_propios[a,i])*(datos[row_name,i]-u) # otra posible opción
    }
  }
  rm(i)
  rm(a)
  
  names(contrib) <- col_names
  
  #print("")
  #cat("Vector de contribuciones: \n", contrib)
  #print("")
  #cat("Sumatorio del vector de contribuciones (valor de T2-Hotelling): \n", sum(contrib))
  return(barplot(contrib, las=2, cex.names = 0.8, main=paste('Contribuciones de cada variable a la T2-Hotelling de', nombres_jugadores[as.character(row_name),"Name"]), cex.main = 2))
}


##### Para SCR
ContriSCR = function(E, SCR, row_name, nombres_jugadores) {
  # E es la matriz de residuos del modelo 
  # SCR es la suma de cuadrados residual
  eind<-E[row_name,]
  signo<-sign(eind)
  contrib<-(signo*(eind^2)/SCR[row_name])*100

  rownames(contrib) = rownames(E)
  
  return(barplot(contrib, las=2, cex.names = 0.8, main=paste('Contribuciones de cada variable a la SCR de', nombres_jugadores[as.character(row_name),"Name"]), cex.main = 2))
}

ContriT2(fifa_numericas2, modelo = res.pca, row_name = 1, K = 6, fifa_paralelo)
ContriSCR(E = myE, SCR = mySCR, row_name = 1, nombres_jugadores = fifa_paralelo)
```

Es fácil observar que las variables Value y Wage tienen una contribución enorme y desproporcionada con respecto a la mayoría de las otras variables, esto tiene sentido con respecto a lo que veíamos en el análisis exploratorio inicial. Por otra parte, estas variables no deberían ser muy influyentes en nuestro objetivo de agrupamientos de jugadores, pero sí podríamos considerarlas como variables de respuesta en nuestro objetivo de predicción de calidad de jugadores. Es por estas dos razones que decidimos considerarlas como auxiliares al volver a ajustar un nuevo modelo. También decidimos considerar como auxiliar la variable International.Reputation.


### Reajuste del modelo 

Realizamos un nuevo PCA marcando las variables mencionadas como auxiliares numéricas (además de las categóricas consideradas anteriormente) y consultamos de nuevo los gráficos de $T^2$-Hotelling y SCR.

```{r, include=FALSE}
res.pca_2 = PCA(fifa, scale.unit = TRUE, graph = FALSE, ncp = 6, 
              quali.sup = which(descFifa$tipo == "categorical"), quanti.sup = 6:8) #esas 3 como auxiliares
eig.val <- get_eigenvalue(res.pca)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca_2, addlabels = TRUE) +
  geom_hline(yintercept=VPmedio, linetype=2, color="red")
```


```{r T2_SCR, echo=FALSE}
#{r T2, fig.width=5, fig.height=5}

K = 6
misScores = res.pca_2$ind$coord[,1:K]
miT2 = colSums(t(misScores**2) / eig.val[1:K])
I = nrow(fifa)
F95 = K*(I**2 - 1)/(I*(I - K)) * qf(0.95, K, I-K)
F99 = K*(I**2 - 1)/(I*(I - K)) * qf(0.99, K, I-K)
alarma95 = which(miT2 > F95)
alarma99 = which(miT2 > F99)
T2_eliminar2 <- which(miT2 > 3*F99)
#fifa <- fifa[-T2_eliminar,]

plot(1:length(miT2), miT2, type = "l", xlab = "Jugadores de FIFA", ylab = "T2", main = "Distancia de Mahalanobis al centro")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)



misLoadings = sweep(res.pca_2$var$coord, 2, sqrt(res.pca_2$eig[1:K,1]), FUN="/") # para calcular loadings 
fifa_numericas3 <- scale(fifa[,descFifa$tipo == "numerical"], center = T, scale = T) 
fifa_numericas3 <- fifa_numericas3[,-c(4,5,6)]
#X = as.matrix(fifa_numericas2)
#X[is.na(X)] = 0
myE = fifa_numericas3 - misScores %*% t(misLoadings) 
mySCR = rowSums(myE^2)  
mySCR[is.na(mySCR)] = 0 #hacemos esto para que no de NA
g = var(mySCR)/(2*mean(mySCR))
h = (2*mean(mySCR)^2)/var(mySCR)
chi2lim95 = g*qchisq(0.95, df = h)
chi2lim99 = g*qchisq(0.99, df = h)
SCR_eliminar2 <- which(mySCR > 3*chi2lim99) #length(which(mySCR > chi2lim99))/17918
#fifa <- fifa[-SCR_eliminar,]

plot(1:length(mySCR), mySCR, type = "l", main = "Distancia al modelo", 
     ylab = "SCR", xlab = "Jugadores de FIFA")
abline(h = chi2lim95, col = "orange", lty = 2)
abline(h = chi2lim99, col = "red3", lty = 2)
```

Después de este reajuste, los valores anómalos y atípicos no superarían ni dos veces los límites de 99% en ningún caso, aunque el número de alarmas aumenta ligeramente. Respecto a las alarmas de $T^2$-Hotelling para el 95% y el 99% se nos quedarían, respectivamente, en `r round(nrow(as.matrix(which(miT2 > F95)))/17918, 4)`% y `r round(nrow(as.matrix(which(miT2 > F99)))/17918, 4)`%. Para la SCR, se quedaría en  `r round(nrow(as.matrix(which(mySCR > chi2lim95)))/17918, 4)`% y `r round(nrow(as.matrix(which(mySCR > chi2lim99)))/17918, 4)`%. Ahora podemos dar el modelo como validado.


### Interpretación del modelo
#### Gráfico de loadings

Trataremos de interpretar los distintos procesos latentes que se obtienen de nuestras variables mediante gráficos de *loadings*.

```{r, echo=FALSE, warning=FALSE, fig.width=10, fig.height=10}
#, fig.width=10, fig.height=10
fviz_pca_var(res.pca_2, axes = c(1,2), repel = TRUE, col.var = "contrib", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup","quali")) #, select.var = list(contrib = 70) 
fviz_pca_var(res.pca_2, axes = c(3,4), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),invisible = c("quanti.sup", "quali"), select.var = list(contrib = 30) )
fviz_pca_var(res.pca_2, axes = c(5,6), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup", "quali"))
#corrplot(res.pca_2$var$contrib, is.corr=FALSE, tl.col = 1, win.asp = 0.5, cl.ratio = 0.3, cl.cex = 0.8)

```

```{r,echo=FALSE,fig.height=9}

#podemos meter este gráfico sin comentar nada de momento, no sobra tampoco
corrplot(res.pca_2$var$cos2, is.corr=FALSE, tl.col = 1, win.asp = 0.6, cl.ratio = 0.4, cl.cex = 0.8, tl.cex = 0.7)
```

El primer gráfico de loadings nos muestra cómo la **primera componente** es la que más inercia explica con diferencia. Esto es porque separa las variables de habilidades de porteros (no se ven los nombres, son las flechas naranjas en sentido negativo de la primera componente) y de jugadores no porteros, y estas variables tienen una fuerte contribución a dicha componente. La contribución de las variables Weight y Height en la primera componente es considerable también. Por otra parte, al parecer, la primera componente indica que apenas hay relación entre tener buenas puntuaciones en las variables de habilidades y tener fuerza, es decir, no hay correlación entre ser fuerte y ser un buen futbolista, tengas la posición en el campo que tengas. No es hasta que nos fijamos en **la segunda componente** que podemos identificar mejor otras estructuras latentes: dicha componente sugiere, por ejemplo, que ser bueno metiendo goles, ágil con el balón y/o mantener bien el equilibrio **no** tiene correlación con ser un jugador agresivo en general, pero sí tiene correlación negativa con pesar y medir más. Por otro lado, la segunda componente ayuda a separar las variables Height, Weight, Position_CEN y Strength de las variables Position_EXT, Position_MED, Position_MEDOF y Position_DEL de tal manera que se establecen relaciones negativas entre estos dos conjuntos de variables, que significa que los jugadores de posición centro tienden a ser más corpulentos, a diferencia de los extremos, mediocentros, mediocentro ofensivos y delanteros. Las relaciones mencionadas hasta ahora parecen ser lógicas. Se puede mencionar algunos aspectos interesantes, y es que, aunque sean pequeñas (pero a tener en cuenta al haber eigenvalues altos), las relaciones positivas con la preferencia del uso de pie derecho y las variables de porteros, o la relación positiva entre la preferencia del pie izquierdo y la fortaleza física, pases largos y cortos, la compostura ante la presión defensora y la velocidad moviendo el balón, o que los futbolistas más mayores tiendan a ser laterales, mediocentro defensivos y que salten más. Preferred.foot_Right y Preferred.foot_Left están negativamente correlacionadas con la misma cantidad de loading, ocurre de forma paralela para el resto de componentes.

Si observamos el gráfico de loadings de la **tercera y cuarta componente**, donde se muestran las 30 variables con más contribución, de las conclusiones que podemos sacar y con respecto a lo mencionado en las anteriores, algunas son similares y otras contradictorias. Se puede observar que la tercera componente separa aceptablemente las variables Balance y Position_LAT de Height, Weight, Stregth, Vision, Potential, Composture, Age, Reactions, Overall, etc. La cuarta componente relaciona positivamente la posición de delantero con la precisión de golpear con la cabeza y la preferencia del pie derecho, relaciona de la misma forma el pie izquierdo con el equilibrio, posición lateral y la capacidad de quitar la pelota tanto agresiva como relajadamente. Estos dos últimos conjuntos mencionados se relacionan negativamente entre ellos y están incorrelacionados con el grupo de las variables positivamente correlacionadas con Reactions y Overall.

Finalmente, si observamos el gráfico de loadings de la **quinta y sexta componente**, cabe destacar que las variables que más explicadas por la quinta componente son Preferred.Foot_Left y Preferred.Foot_Right, con una lógica correlación negativa entre ellas, como mencionábamos antes. Otras relaciones entre variables a destacar, para ambas componentes son por ejemplo los delanteros o laterales, que tienen relación positiva con potencia de salto, velocidad y aceleración; o los mediocentros, tanto defensivos como ofensivos, para los que encontramos relaciones positivas con las variables relacionadas con pases, visión de juego o control de balón. Relaciones bastante acordes con la realidad. Cabe destacar que la altura y el peso no están relacionados con ninguna de las posiciones citadas previamente.


#### Gráfico de scores

Una vez estudiados los comportamientos latentes, podemos consultar los gráficos de *scores*. Dichos scores los hemos coloreado según la posición del jugador.

```{r, warning=FALSE, echo=FALSE}
fviz_pca_ind(res.pca_2, axes = c(1,2), geom = c("point", "text"), addEllipses = F, habillage = "Position")
fviz_pca_ind(res.pca_2, axes = c(3,4), geom = c("point", "text"), addEllipses = F, habillage = "Position")
fviz_pca_ind(res.pca_2, axes = c(5,6), geom = c("point", "text"), addEllipses = F, habillage = "Position")
```

Consultando el primer gráfico, queda clara la capacidad de explicación de variabilidad de la primera componente, ya que quedan claramente alejados dos conjuntos de individuos, siendo el más pequeño (coloreado de rosa) el de los porteros, y el más grande el del resto de los futbolistas. En el mayor conjunto podemos llegar a discernir distintas nubes de puntos, con el inconveniente de estar muy solapadas. Sí que se podría disgregar la nube de jugadores de posición centro con parte de la de delanteros, pero para esta segunda nube es difícil diferenciar el resto de posiciones.

En el segundo gráfico se nos presenta una situación similar a la anterior; las nubes fáciles de separar, si se toman por separado, son las de porteros de y de centros. Si no, estas dos componentes no contribuyen al distanciamiento entre scores según la posición. 

Curiosamente, en el tercer gráfico, donde las componentes explican menor variabilidad, sí se muestra una mejor separación entre las distintas nubes de posiciones. Es cierto que tenemos casi dos mismas agrupaciones generales de individuos, pero no están tan solapadas como antes. Esto se debe a la fuerte contribución de las variables Preferred.Foot_Left y Preferred.Foot_Right a la quinta componente, como veíamos antes en los gráficos de loadings. Por tanto, en este tercer gráfico de scores, tenemos dos conjuntos similares: el de la izquierda se corresponde con aquellos jugadores que prefieren el pie derecho, y el de la derecha con los que prefieren el pie izquierdo.

Con estos resultados, podemos pasar al siguiente método para completar el primer objetivo del trabajo: *clustering*.



#PCA. Separacion jugadores y porteros. 

```{r}
fifa_jugadores = subset(fifa, Position != "POR")
fifa_jugadores = fifa_jugadores[,setdiff(colnames(fifa_jugadores), c("GKDiving","GKHandling","GKPositioning","GKKicking","GKReflexes","Position_POR"))]
```

```{r}
descFifa_jugadores = data.frame("variable" = colnames(fifa_jugadores),
                      "tipo" = c("numerical", "categorical",
                                 rep("numerical", 2), "categorical", 
                                 rep("numerical", 2), rep("categorical", 4),
                                 rep("numerical", 40)), stringsAsFactors = FALSE)
rownames(descFifa_jugadores) = descFifa_jugadores$variable
```

```{r}
res.pca_jugadores = PCA(fifa_jugadores, scale.unit = TRUE, graph = FALSE, ncp = 6, 
              quali.sup = which(descFifa_jugadores$tipo == "categorical"), quanti.sup = 6:8) #esas 3 como auxiliares
eig.val <- get_eigenvalue(res.pca_jugadores)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca_jugadores, addlabels = TRUE) +
  geom_hline(yintercept=VPmedio, linetype=2, color="red")
```

```{r, echo=FALSE, warning=FALSE, fig.width=10, fig.height=10}
#, fig.width=10, fig.height=10
fviz_pca_var(res.pca_jugadores, axes = c(1,2), repel = TRUE, col.var = "contrib", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup","quali")) #, select.var = list(contrib = 70) 
fviz_pca_var(res.pca_jugadores, axes = c(3,4), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),invisible = c("quanti.sup", "quali"), select.var = list(contrib = 30) )
fviz_pca_var(res.pca_jugadores, axes = c(5,6), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup", "quali"))
#corrplot(res.pca_2$var$contrib, is.corr=FALSE, tl.col = 1, win.asp = 0.5, cl.ratio = 0.3, cl.cex = 0.8)
```

```{r, warning=FALSE, echo=FALSE}
fviz_pca_ind(res.pca_jugadores, axes = c(1,2), geom = c("point", "text"), addEllipses = F, habillage = "Position")
fviz_pca_ind(res.pca_jugadores, axes = c(3,4), geom = c("point", "text"), addEllipses = F, habillage = "Position")
fviz_pca_ind(res.pca_jugadores, axes = c(5,6), geom = c("point", "text"), addEllipses = F, habillage = "Position")
```

```{r}
fifa_porteros = subset(fifa, Position == "POR")
```

```{r}
descFifa_porteros = data.frame("variable" = colnames(fifa),
                      "tipo" = c("numerical", "categorical",
                                 rep("numerical", 2), "categorical", 
                                 rep("numerical", 5), "categorical",
                                 rep("numerical", 46)), stringsAsFactors = FALSE)
rownames(descFifa_porteros) = descFifa_porteros$variable
```



```{r}
res.pca_porteros = PCA(fifa_porteros, scale.unit = TRUE, graph = FALSE, ncp = 6, 
              quali.sup = which(descFifa_jugadores$tipo == "categorical"), quanti.sup = 6:8) #esas 3 como auxiliares
eig.val <- get_eigenvalue(res.pca_porteros)
VPmedio = 100 * (1/nrow(eig.val))
fviz_eig(res.pca_porteros, addlabels = TRUE) +
  geom_hline(yintercept=VPmedio, linetype=2, color="red")

```

```{r, echo=FALSE, warning=FALSE, fig.width=10, fig.height=10}
#, fig.width=10, fig.height=10
fviz_pca_var(res.pca_porteros, axes = c(1,2), repel = TRUE, col.var = "contrib", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup","quali")) #, select.var = list(contrib = 70) 
fviz_pca_var(res.pca_porteros, axes = c(3,4), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),invisible = c("quanti.sup", "quali"), select.var = list(contrib = 30) )
fviz_pca_var(res.pca_porteros, axes = c(5,6), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup", "quali"))
#corrplot(res.pca_2$var$contrib, is.corr=FALSE, tl.col = 1, win.asp = 0.5, cl.ratio = 0.3, cl.cex = 0.8)

```

```{r, warning=FALSE, echo=FALSE}
fviz_pca_ind(res.pca_porteros, axes = c(1,2), geom = c("point", "text"), addEllipses = F, habillage = "Position")
fviz_pca_ind(res.pca_porteros, axes = c(3,4), geom = c("point", "text"), addEllipses = F, habillage = "Position")
fviz_pca_ind(res.pca_porteros, axes = c(5,6), geom = c("point", "text"), addEllipses = F, habillage = "Position")
```

# CLUSTERING

Para realizar el procedimiento de clustering utilizamos las coordenadas resultantes del PCA, ya que como hemos visto anteriormente las variables de nuestros datos se encuentran muy correlacionadas. Para no perder la variabilidad no explicada por las 6 componentes que habíamos seleccionado en el análisis de componentes principales, añadimos la suma de cuadrados residual como una componente más, y así recuperamos toda la variabilidad de los datos originales. A partir de los resultados del PCA hemos visto ya una tendencia de agrupamiento muy clara, que separa a los porteros de los jugadores en dos grupos bien diferenciados. En este análisis nos centraremos principalmente en si existen tendencias de agrupamiento en los jugadores, por lo que en primer lugar calculamos la SCR de cada jugador y se añade como una componente más. 

```{r new df with PCA applied}
df_after_PCA = as.data.frame(res.pca_2$ind$coord)
df_after_PCA = cbind(df_after_PCA, mySCR)
midist = get_dist(df_after_PCA, stand=FALSE, method = "euclidean")
```

A partir de los resultados del PCA hemos visto ya una tendencia de agrupamiento muy clara, que separa a los porteros de los jugadores en dos grupos bien diferenciados. En este análisis nos centraremos principalmente en si existen tendencias de agrupamiento en los jugadores, por lo que en primer lugar calculamos la SCR de cada jugador y se añade como una componente más. 

```{r SCR, echo=FALSE}
K = 6
misScores_jug = res.pca_jugadores$ind$coord[,1:K]
misLoadings_jug = sweep(res.pca_jugadores$var$coord, 2, sqrt(res.pca_jugadores$eig[1:K,1]), FUN="/") # para calcular loadings 
fifa_numericas_jug <- scale(fifa_jugadores[,descFifa_jugadores$tipo == "numerical"], center = T, scale = T) 
fifa_numericas_jug <- fifa_numericas_jug[,-c(4,5)]
#X = as.matrix(fifa_numericas2)
#X[is.na(X)] = 0
mat = misScores_jug %*% t(misLoadings_jug)
myE_jug = fifa_numericas_jug - mat
mySCR_jug = rowSums(myE_jug^2)  
```

```{r}
df_jugadores_after_PCA = as.data.frame(res.pca_jugadores$ind$coord)
df_jugadores_after_PCA = cbind(df_jugadores_after_PCA, mySCR_jug)
midist_jugadores = get_dist(df_jugadores_after_PCA, stand=FALSE, method = "euclidean")
```

Al realizar el PCA y obtener los gráficos de scores, hemos podido observar como nuestros datos tienden a agruparse en dos clusters bien diferenciados. Esto se debe a que una parte de nuestra base de datos corresponde a porteros, quienes tienen valores muy bajos en la mayoría de variables referentes a las cualidades de juego. Respectivamente, el resto de jugadores tiene valores muy bajos para las variables que especifican cualidades de los porteros, lo que genera una gran diferencia. 

A continuación, estimaremos el número óptimo de clusters con el algoritmo de kmedias y utilizando como criterio el coeficiente de Silohuette. A pesar de que lo óptimo sería probar con mas criterios como 'wss' o el estadístico de gap para contrastar los resultados, utilizamos unicamente el de Silhouette ya que estos dos últimos metodos no funcionan debido a las dimensiones de nuestro dataframe. 

Se aplica a la base de datos completa para reafirmar lo visto en el PCA, es decir, los dos clusters bien diferenciados, y al conjunto de los jugadores sin los porteros, para estudiar posteriormente si existen tendencias de agrupamiento. 

```{r koptKmeans, fig.width=3, fig.height=3}
#solo admite la distancia euclidea. 
#fviz_nbclust(x = df_after_PCA, FUNcluster = kmeans, method = "silhouette", 
#             k.max = 10, verbose = FALSE) +
#  labs(title = "K-means")


fviz_nbclust(x = df_jugadores_after_PCA, FUNcluster = kmeans, method = "silhouette", 
             k.max = 10, verbose = FALSE) +
  labs(title = "K-means")

par(mfrow=c(1,1))
```

Como se esperaba, el número de clusters que maximiza el coeficiente de Silohuette es 2, si obviamos los porteros, este coeficiente baja significativamente. El numero óptimo de clusters para los jugadores sigue siendo 2, y baja para 3, 4 y 5 clusters manteniendose en un valor similar para estos tres. Probamos a continuación con el metodo de k-medoides. 

```{r particion K-medoides}
#fviz_nbclust(x = df_jugadores_after_PCA, FUNcluster = cluster::pam, method = "silhouette", 
#             k.max = 10, verbose = FALSE) +
#  labs(title = "Num. clusters")
```


Observamos que tanto para el metodo de k-medias como para el de k-medoides, el número de clusters que maximiza el coeficiente de Silohuette es 2, a pesar de esto, si seleccionamos dos clusters es posible que se agrupen en un mismo cluster jugadores que no tengan demasiada relación entre sí al tratarse de clusters tan grandes. En el metodo de k-medias podemos ver como para 3, 4 y 5 clusters, tenemos un coeficiente de silohuette similar, y algo más elevado que para el resto de clusters.  

Debido a que los resultados son similares, es dificil decantarse por uno de los metodos. Comparamos las clasificaciones de k-medias y k-medoides para 2, 3 y 5 clusters con el coeficiente de Silohuette. Devolvemos el coeficiente de silohuette para cada individuo por cluster en cada método. 

Para calcular los clusters con los medoides, usaremos el metodo clara, que divide los datos en k grupos utilizando el mismo algoritmo que pam. Este método permite manejar conjuntos de datos mucho más grandes. 


```{r cluster final k-means}
clust_means_1 <- kmeans(df_jugadores_after_PCA, centers = 2, nstart = 20)
clust_means_2 <- kmeans(df_jugadores_after_PCA, centers = 3, nstart = 20)
clust_means_3 <- kmeans(df_jugadores_after_PCA, centers = 5, nstart = 20)
set.seed(100)
```

```{r cluster final k-medoides}
clust_medoides_1 <- clara(df_jugadores_after_PCA, 2, metric = "euclidean", stand = FALSE, samples = 50, pamLike = TRUE)
clust_medoides_2 <- clara(df_jugadores_after_PCA, 3, metric = "euclidean", stand = FALSE, samples = 50, pamLike = TRUE)
clust_medoides_3 <- clara(df_jugadores_after_PCA, 5, metric = "euclidean", stand = FALSE, samples = 50, pamLike = TRUE)
```

```{r comparacion}
par(mfrow = c(1,3))
plot(silhouette(clust_means_1$cluster, midist_jugadores), col=rainbow(2), border=NA, main = "K-MEDIAS")
plot(silhouette(clust_means_2$cluster, midist_jugadores), col=rainbow(3), border=NA, main = "K-MEDIAS")
plot(silhouette(clust_means_3$cluster, midist_jugadores), col=rainbow(5), border=NA, main = "K-MEDIAS")
```

```{r}
par(mfrow=c(1,3))
plot(silhouette(clust_medoides_1$clustering, midist_jugadores), col=rainbow(2), border=NA, main = "K-MEDOIDES")
plot(silhouette(clust_medoides_2$clustering, midist_jugadores), col=rainbow(3), border=NA, main = "K-MEDOIDES")
plot(silhouette(clust_medoides_3$clustering, midist_jugadores), col=rainbow(5), border=NA, main = "K-MEDOIDES")

```

Los resultados obtenidos respectivos al valor medio del coeficiente de silohuette, son similares para los diferentes números de clusters que hemos determinado. Es cierto que para dos clusters, es mejor el agrupamiento según el coeficiente, pero al agrupar tantos individuos en dos grupos tan grandes, es posible que se este añadiendo al mismo grupo jugadores muy diferentes entre sí. Por esto, descartamos 2 como el número óptimo de clusters y decidimos entre 3 y 5. Se observa que en el metodo de kmeans, hay menos jugadores mal clasificados que en kmedoides por lo que nos fijaremos en los resultados de kmeans. Para 3 y 5 clusters, el coeficiente de silohuette es practicamente igual, seleccionaremos en principio 5 clusters, al ser un valor más proximo al número de posiciones reales en las que se dividen los jugadores. Como se observa, el coeficiente de silohuette obtenido es relativamente bajo, más cercano de 0 que de 1, por lo que podemos esperar que no existan unas variables que separen los grupos claramente. A continuación, obtenemos los graficos de scores y loadings para ver que variables influyen de mayor manera a la división en clusters. 


```{r}
clust = factor(clust_means_3$cluster)
set.seed(100)
```

```{r}
par(mfrow=c(1,3))

fviz_pca_ind(res.pca_jugadores, geom = "point", habillage = clust, addEllipses = FALSE,
             palette = rainbow(5), axes = c(1,2))

fviz_pca_var(res.pca_jugadores, axes = c(1,2), repel = TRUE, col.var = "contrib", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup","quali"),select.var = list(name = c("Position_CEN","Position_DEL","Position_MEDOF","Position_MEDDEF","Position_EXT","Position_LAT","Position_MED"))) #, select.var = list(contrib = 70) 

fviz_pca_var(res.pca_jugadores, axes = c(1,2), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),invisible = c("quanti.sup", "quali"), select.var = list(contrib = 30) )
                                                                                                                   
```

```{r}
par(mfrow=c(1,3))

fviz_pca_ind(res.pca_jugadores, geom = "point", habillage = clust, addEllipses = FALSE,
             palette = rainbow(5), axes = c(3,4))
fviz_pca_ind(res.pca_jugadores, geom = "point", habillage = clust, addEllipses = FALSE,
             palette = rainbow(5), axes = c(5,6))

fviz_pca_var(res.pca_jugadores, axes = c(3,4), repel = TRUE, col.var = "contrib", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup","quali"),select.var = list(name = c("Position_CEN","Position_DEL","Position_MEDOF","Position_MEDDEF","Position_EXT","Position_LAT","Position_MED"))) #, select.var = list(contrib = 70) 

fviz_pca_var(res.pca_jugadores, axes = c(3,4), repel = TRUE, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),invisible = c("quanti.sup", "quali"), select.var = list(contrib = 30) )
                                                                                                                   


set.seed(100)
```

En el gráfico de scores, observamos que los individuos no están muy diferenciados por lo general, algo que esperabamos debido al bajo valor del coeficiente de Silohuette. A pesasr de ello, podemos diferenciar ciertos agrupamientos. La segunda componente explica un 17,7% de significación y diferencia al cluster 4 de los cluster 5, que se encuentran bastante mezclados en las primeras dos componentes con el cluster 2. La primera dimensión, que explica un 29,6% de la variabilidad de los datos, separa algo al cluster 1 de los clusters 3 y 4. Como se puede observar, en las primeras dos dimensiones tenemos cierta separación entre los clusters 1, 3, 4 y 5. Obtenemos las componentes 3 y 4 para ver si en estas se observa una separación mejor de estos grupos. En la tercera y cuarta dimensión, vemos que se consigue separar el cluster 5, mientras que el resto de agrupaiones se encuentran solapadas. Con los gráficos de loadings, representamos las posiciones de los jugadores para ver si los clusters obtenidos separan adecuadamente según la posición del jugador. También realizamos la representación para las variables respectivas a las carácteristicas de cada jugador. 

A la vista de los gráficos de scores y loadings, podemos obtener algunas conclusiones: El cluster 1 está integrado mayoritariamente por jugadores defensivos, que tienen la posición de central. Podemos ver en el gráfico de loadings, la dirección de la variable "Position_CEN", coincidente con el primer cluster y con una contribución razonablementen alta. 

El cluster 2, también estará formado por jugadores que destacan en las habilidades defensivas, pero no necesariamente son centrales. La zona de intersección del primer cluster con el segundo, se encuentra en la dirección de variables como "Standing Tackle", "Sliding Tackle", "Interceptions", "Marking" o "Strenght". Todas son características predominantes en los jugadores que destacan en el físico y en la defensa. La posición Medio Defensivo, también se observa en la dirección del cluster 2, con lo que afirmamos la suposición. 

Por otro lado, vemos que el cluster 3, está formado por aquellos jugadores que destacan en características relacionadas con habilidades ofensivas como "Dribbling", "Finishing" o "Shot Power" por lo que es el cluster indicado si tratamos de buscar un jugador con características de centrocampista ofensivo, delantero y con valores altos en las características por lo general. 

El cluster 4, se encuentra en una zona que no esta relacionada con ninguna posición en específico, pero esta correlacionado con muchas variables más generales y no tan especificas para alguna posición en concreto. Variables como "Overall", "Reactions", "Short Passing" y "Ball Controll, son algunas de las que más contribución tienen en este cluster. Este cluster estará integrado por jugadores con valores relativamente altos para el conjunto de variables en general y más ofensivos que defensivos. 

Por último, en la tercera dimensión el cluster 5 se separa del resto y usando el gráfico de loadings podemos ver que esta integrado principalmente por delanteros con características físicas destacadas, como "Strenght", "Weight", o "Height". Por lo que puede ser el cluster indicado para buscar un delantero con estas características. 

En conclusión, y a pesar de no obtener una clara separación entre los diferentes tipos de jugadores, el análisis clustering puede ser útil para la busqueda de jugadores con determinadas características. Un usuario del juego, conociendo las variables que mayor contribución tienen a cada cluster, puede reducir la busqueda a uno de los grupos para encontrar el jugador óptimo con las características que busca. 

# Tercer método - PLS
## Objetivo PLS

Por medio de este estudio buscamos predecir los valores de las variables *Value*, *Wage* e *International.Reputation*. 
Como vimos en el método PCA, había grandes diferencias entre los jugadores que ocupan la posición portero y los del resto de posiciones, ya que son posiciones con características bastante diferentes. Por ello, hemos decidido realizar dos análisis PLS diferentes, uno para los porteros y otro para el resto de jugadores de campo.


## Implementación del método PLS para porteros

Para poder realizar el análisis sobre los porteros, seleccionamos únicamente los jugadores pertenecientes a esta posición, y realizamos una partición del 75% de los datos para el entrenamiento y 25% para evaluar los resultados.

Además, seleccionamos las variables a predecir, en nuestro caso Value, Wage e International.Reputation, y las variables predictoras, que son las mismas que usamos para el modelo PCA.
 
```{r, include=FALSE}
set.seed(300)


#fifa_p = fifa[which(fifa$Position == "POR"),]
fifa_p = subset(fifa, Position == "POR")
#fifa_p = fifa[which(fifa$Position_POR == 1),]
#rownames(fifa_p) %in% rownames(fifa_paralelo[which(fifa_paralelo$Position == "GK"),])

# Partición 75% train test
hv_index_p <- createDataPartition(fifa_p$Value, p = .75, list = FALSE)

tr_p <- fifa_p[hv_index_p, ]
te_p <- fifa_p[-hv_index_p, ]

Y_train_p = tr_p[,c(6,7,8)]
Y_test_p = te_p[,c(6,7,8)]
X_train_p = tr_p[,c(1,3,4,9,12:49)] # - Nationality, Club, Skill.Moves, Position, Position_CEN, Wage, Value, International.Reputation, Position_LAT, Position_MED, Position_MEDDEF, Position_MEDOF, Position_POR, Position_DEL, Position_EXT
X_test_p = te_p[,c(1,3,4,9,12:49)]
```


### Selección de variables

Pero primero, vamos a seleccionar aquellas variables que sean significativas en el modelo PLS. A lo que esto se refiere es que a pesar de que contemos con 42 regresores, no necesariamente necesitaremos usar todos para conseguir un buen modelo, además que tener menos variables facilitará la interpretación. Por ello, realizamos un modelo PLS **inicial** con los datos de entrenamiento centrados y escalados y usando validación cruzada 10-fold. Escogeremos un número de componentes que aporte unos buenos valores de $R^2$ y $Q^2$ (en este caso 3 componentes).

```{r, include=FALSE}
mypls_p = opls(x = X_train_p, y = as.matrix(Y_train_p), predI = 10, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")
```

```{r, message = FALSE, warning=FALSE, include=FALSE}
plot(1:10, mypls_p@modelDF$`R2Y(cum)`, type = "o", pch = 16, col = "blue3",
     lwd = 2, xlab = "Componentes", ylab = "", main = "PLS porteros")
lines(1:10, mypls_p@modelDF$`Q2(cum)`, type = "o", pch = 16, col = "red3",
      lwd = 2)
abline(h = 0.5, col = "red3", lty = 2)
legend("topleft", c("R2Y", "Q2"), lwd = 2, col = c("blue3", "red3"), bty = "n")
```

```{r, include=FALSE}
mypls_p = opls(x = X_train_p, y = as.matrix(Y_train_p), predI = 3, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")
```

Una vez obtenido este modelo inicial, vamos a estudiar los valores de VIP de cada variable para saber la importancia relativa que tiene cada una en el modelo. Como criterio de aceptación, conservaremos solo aquellas que mayores o iguales al valor de VIP de 0.8. Si tienen un valor VIP menor al mencionado, podremos considerar que son irrelevantes y/o estadísticamente no significativas.

```{r,fig.width=18, fig.height=7}
barplot(sort(mypls_p@vipVn, decreasing = TRUE), main = "VIP porteros", las = 2, cex.names = 0.8, cex.main = 2)
abline(h = 1, col = "orange", lty = 2, lwd = 2)
abline(h = 0.8, col = "red3", lty = 2, lwd = 2)

barplot(mypls_p@coefficientMN[,1],main = "Coeficientes Value", las =2, cex.names = 0.8, cex.main = 2)

barplot(mypls_p@coefficientMN[,2],main = "Coeficientes Wage", las =2, cex.names = 0.8, cex.main = 2)

barplot(mypls_p@coefficientMN[,3],main = "Coeficientes International.Reputation", las =2, cex.names = 0.8, cex.main = 2)
```

```{r,include=FALSE}
X_train_p = X_train_p[,mypls_p@vipVn >= 0.8] 
X_test_p = X_test_p[,mypls_p@vipVn >= 0.8]
```

Son `r length(which(mypls_p@vipVn < 0.8))` las variables que no superan el valor de VIP de 0.8. Tras esto, el número de variables explicativas útiles se queda en 22.


### Elección del número de componentes

Reajustamos el modelo sin estas variables que no superan el criterio de VIP, de nuevo con validación cruzada 10-fold. Recurriremos de nuevo a $R^2$ y $Q^2$ para elegir el número de componentes PLS.

```{r, include=FALSE}
mypls_p = opls(x = X_train_p, y = as.matrix(Y_train_p), predI = 10, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")
```

```{r, message = FALSE, warning=FALSE, echo=FALSE}
plot(1:10, mypls_p@modelDF$`R2Y(cum)`, type = "o", pch = 16, col = "blue3",
     lwd = 2, xlab = "Componentes", ylab = "", main = "PLS porteros")
lines(1:10, mypls_p@modelDF$`Q2(cum)`, type = "o", pch = 16, col = "red3",
      lwd = 2)
abline(h = 0.5, col = "red3", lty = 2)
legend("topleft", c("R2Y", "Q2"), lwd = 2, col = c("blue3", "red3"), bty = "n")
```

```{r, include=FALSE}
mypls_p = opls(x = X_train_p, y = as.matrix(Y_train_p), predI = 4, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")
```


### Validación con T2 Hotelling y SCR

Antes de interpretar el modelo, vamos a validarlo. Consideraremos por validos aquellos valores que no superen 2 veces los límites de confianza del 99%. A diferencia del anterior objetivo realizado con PCA y clustering, ahora sí podríamos considerar eliminar algún individuo muy anómalo o atípico, ya que el objetivo es predecir las 3 variables antes mencionadas, y no es necesario mantener todos los jugadores.

```{r, echo=FALSE}
#T2-Hotelling
misScores = mypls_p@scoreMN
varT = apply(misScores, 2, var)
miT2 = colSums(t(misScores**2) / varT)
N = nrow(X_train_p)
A = 4
F95 = A*(N**2 - 1)/(N*(N - A)) * qf(0.95, A, N-A)
F99 = A*(N**2 - 1)/(N*(N - A)) * qf(0.99, A, N-A)
plot(1:length(miT2), miT2, type = "l", ylab = "T2",
     main = "PLS: T2-Hotelling", xlab = "Porteros")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)

#SCR
myT = mypls_p@scoreMN
myP = mypls_p@loadingMN
myE = scale(X_train_p) - myT%*%t(myP) 
mySCR = rowSums(myE^2)   # SPE 
plot(1:length(mySCR), mySCR, type = "l", main = "PLS: SCR porteros", 
     ylab = "d", xlab = "Porteros")
g = var(mySCR)/(2*mean(mySCR))
h = (2*mean(mySCR)^2)/var(mySCR)
chi2lim = g*qchisq(0.95, df = h)
abline(h = chi2lim, col = "orange", lty = 2, lwd = 2)
abline(h = g*qchisq(0.99, df = h), col = "red3", lty = 2, lwd = 2)
#which(mySCR == max(mySCR))
#which(mySCR > 2*g*qchisq(0.99, df = h))
```

En el gráfico de $T^2$-Hotelling vemos que hay pocos porteros que pasen el límite del 95%-99%, y decidimos no eliminarlos ya que al igual que en PCA, los porteros anómalos son aquellos con mejores características y que se diferencian en gran medida de los porteros mediocres, que son la mayoría. Por encima del límite de confianza de 95% tenemos `r dim(as.matrix(which(miT2 > F95)))[1]` observaciones y por encima del límite de 99% tenemos `r dim(as.matrix(which(miT2 > F99)))[1]` observaciones, que respectivamente son el `r round(nrow(as.matrix(which(miT2 > F95)))/1495, 3)`% y el `r round(nrow(as.matrix(which(miT2 > F99)))/1495, 3)`%. Respecto a la suma de cuadrados residual, tampoco tenemos datos demasiado atípicos o anómalos, como podemos observar en el gráfico. Por tanto, damos por validado el modelo PLS de porteros.


### Relación lineal entre scores porteros

Por otro lado, si observamos la relación entre los scores de los porteros, vemos que hay una tendencia lineal donde se encuentran la mayoría de porteros, que se acaba convirtiendo en exponencial para la primera y segunda componentes, donde no hay casi valores. Esta exponencialidad puede ser debida a los porteros "anómalos" que son los importantes.

Cabe destacar que esto podría arreglarse mediante el uso de transformaciones en los datos, repitiéndo el análisis pero en vez de ser 'Y' las variables a predecir siendo 'ln(Y)', pero es una tarea muy compleja en la que no vamos a indagar que podrá ser desarrollada en un futuro.


```{r, fig.width=16, fig.height=4, echo=FALSE}
# t vs u
par(mfrow = c(1,4))
plot(mypls_p@scoreMN[,1], mypls_p@uMN[,1], xlab = "t", ylab = "u",
     main = "Componente 1", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_p@scoreMN[,2], mypls_p@uMN[,2], xlab = "t", ylab = "u",
     main = "Componente 2", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_p@scoreMN[,3], mypls_p@uMN[,3], xlab = "t", ylab = "u",
     main = "Componente 3", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_p@scoreMN[,4], mypls_p@uMN[,4], xlab = "t", ylab = "u",
     main = "Componente 4", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)

tvsu_1 <- diag(cor(mypls_p@scoreMN, mypls_p@uMN))
```


### Interpretación del modelo PLS porteros

Los siguientes gráficos nos servirán para interpretar el modelo PLS.

```{r, fig.width=15, fig.height=6}
par(mfrow = c(1,2))
plot(x = mypls_p, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(1:2), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)
plot(x = mypls_p, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(3:4), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)
```

```{r, fig.width=15, fig.height=6}
par(mfrow = c(1,2))
plot(x = mypls_p, typeVc = "xy-weight",
     parCexN = 0.8, parCompVi = c(1:2), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)

plot(x = mypls_p, typeVc = "xy-weight",
     parCexN = 0.8, parCompVi = c(3:4), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)
```


### Predicciones con PLS porteros

Antes de predecir con la muestra de test final, realizamos una primera predicción para ver cómo funciona nuestro modelo. Observamos cómo el modelo se ajusta en un principio a los datos pero luego no lo consigue.

```{r, fig.width=12, fig.height=8, echo=FALSE}
# Observados versus predichos
Ypred = predict(mypls_p)
Ypred[,3]=round(Ypred[,3])

par (mfrow = c(2,3))
for (i in 1:ncol(Y_train_p)) {
  plot(Y_train_p[,i], Ypred[,i], asp = 1, main = colnames(Y_train_p)[i],
     xlab = "observado", ylab = "predicho")
abline(a=0, b=1, col = "red3", lwd = 2, lty = 2)
}
```


### Predicciones para test porteros

Finalmente, realizamos las predicciones con nuestros datos de test. Como habíamos observado antes, el modelo consigue ajustar en un principio a los datos, pero luego se desvía infravalorando bastante a los porteros con valores altos. Esto puede ser debido a que el modelo se ajusta bastante a la mayoría, que son los porteros mediocres, no consiguiendo bien predecir el valor de los porteros importantes, que son menos.

```{r, fig.width=12, fig.height=8, echo=FALSE}
# Observados versus predichos
Ypred = predict(mypls_p, X_test_p)
Ypred[,3]=round(Ypred[,3])

par (mfrow = c(2,3))
for (i in 1:ncol(Y_test_p)) {
  plot(Y_test_p[,i], Ypred[,i], asp = 1, main = colnames(Y_test_p)[i],
     xlab = "observado", ylab = "predicho")
abline(a=0, b=1, col = "red3", lwd = 2, lty = 2)
}
```





## Implementación del método PLS para jugadores

En segundo lugar, realizamos el análisis para los jugadores, seleccionando únicamente los jugadores que no pertenezcan a la posición "portero", y realizamos de nuevo una partición del 75% de los datos para el entrenamiento y 25% para evaluar los resultados.

Las variables a predecir son las mismas que en el caso de los porteros.


```{r, include=FALSE}
set.seed(450)

fifa_j = fifa[which(fifa$Position != 'POR'),]

#fifa_j = fifa_j[which(fifa_j$Value > 2200000),]
#fifa_j = fifa_j[which(fifa_j$Value < max(fifa_j)),]

# Partición 75% train test
hv_index_j <- createDataPartition(fifa_j$Value, p = .75, list = FALSE)

tr_j <- fifa_j[ hv_index_j, ]
te_j <- fifa_j[-hv_index_j, ]

Y_train_j = tr_j[,c(6,7,8)]
Y_test_j = te_j[,c(6,7,8)]
X_train_j = tr_j[,c(1,3,4,9:10,12:42,48:56)] # - Nationality, Club, Value, Wage, International.Reputation, Position, GKDiving, GKHandling, GKKicking, GKPositioning
X_test_j = te_j[,c(1,3,4,9:10,12:42,48:56)]
```


### Selección de variables PLS jugadores

Pero primero, vamos a seleccionar aquellas variables que sean significativas en el modelo PLS. A lo que esto se refiere es que a pesar de que contemos con 42 regresores, no necesariamente necesitaremos usar todos para conseguir un buen modelo, además que tener menos variables facilitará la interpretación. Por ello, realizamos un modelo PLS **inicial** con los datos de entrenamiento centrados y escalados y usando validación cruzada 10-fold. Escogeremos un número de componentes que aporte unos buenos valores de $R^2$ y $Q^2$ (en este caso 10 componentes).

```{r, include=FALSE}
#maxNC = min(dim(X_train_j))
mypls_j = opls(x = X_train_j, y = as.matrix(Y_train_j), predI = 20, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")
```


```{r, message = FALSE, warning=FALSE, include=FALSE}
plot(1:20, mypls_j@modelDF$`R2Y(cum)`, type = "o", pch = 16, col = "blue3",
     lwd = 2, xlab = "Componentes", ylab = "", main = "PLS jugadores")
lines(1:20, mypls_j@modelDF$`Q2(cum)`, type = "o", pch = 16, col = "red3",
      lwd = 2)
abline(h = 0.5, col = "red3", lty = 2)
legend("topleft", c("R2Y", "Q2"), lwd = 2, col = c("blue3", "red3"), bty = "n")
```

```{r, include=FALSE}
#PLS con 10 comp.
mypls_j = opls(x = X_train_j, y = as.matrix(Y_train_j), predI = 10, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")
```

Vamos a estudiar los valores de VIP de cada variable, para saber la importancia relativa que tiene cada una en el modelo. Como criterio de aceptación, conservaremos solo aquellas que mayores o iguales al valor de VIP de 0.8.

```{r,fig.width=18, fig.height=7}
barplot(sort(mypls_j@vipVn, decreasing = TRUE), main = "VIP jugadores", las = 2, cex.names = 0.8, cex.main = 2)
abline(h = 1, col = "orange", lty = 2, lwd = 2)
abline(h = 0.8, col = "red3", lty = 2, lwd = 2)

barplot(mypls_j@coefficientMN[,1],main = "Coeficientes Value", las =2, cex.names = 0.8, cex.main = 2)

barplot(mypls_j@coefficientMN[,2],main = "Coeficientes Wage", las =2, cex.names = 0.8, cex.main = 2)

barplot(mypls_j@coefficientMN[,3],main = "Coeficientes International.Reputation", las =2, cex.names = 0.8, cex.main = 2)
```

En este caso, hay `r length(which(mypls_j@vipVn < 0.8))` variables que no superan el valor de VIP de 0.8. Tras esto, el número de variables explicativas útiles se queda en 24.


### Elección del número de componentes Jugadores

```{r,include=FALSE}
X_train_j = X_train_j[,mypls_j@vipVn >= 0.8] 
X_test_j = X_test_j[,mypls_j@vipVn >= 0.8]
```

```{r, include=FALSE}
mypls_j = opls(x = X_train_j, y = as.matrix(Y_train_j), predI = 20, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")

```

```{r, message = FALSE, warning=FALSE, echo=FALSE}
plot(1:20, mypls_j@modelDF$`R2Y(cum)`, type = "o", pch = 16, col = "blue3",
     lwd = 2, xlab = "Componentes", ylab = "", main = "PLS jugadores")
lines(1:20, mypls_j@modelDF$`Q2(cum)`, type = "o", pch = 16, col = "red3",
      lwd = 2)
abline(h = 0.5, col = "red3", lty = 2)
legend("bottomright", c("R2Y", "Q2"), lwd = 2, col = c("blue3", "red3"), bty = "n")
```

Tenemos una situación parecida a la inicial, pero se puede ver ligeramente que con 10 componentes se alcanza el máximo de $Q^2$, por lo que con ese número de componentes PLS las predicciones deberían ser mejores.

```{r, include=FALSE}
mypls_j = opls(x = X_train_j, y = as.matrix(Y_train_j), predI = 10, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")
```


### validacion T2 de Hotelling y SCR Jugadores

De nuevo, validamos el modelo antes de interpretarlo para detectar datos atípicos y anómalos. Consideraremos por validos aquellos valores que no superen 2 veces los límites de confianza del 99%. 

```{r, echo=FALSE}
# Hotelling
misScores = mypls_j@scoreMN
varT = apply(misScores, 2, var)
miT2 = colSums(t(misScores**2) / varT)
N = nrow(X_train_j)
A = 10
F95 = A*(N**2 - 1)/(N*(N - A)) * qf(0.95, A, N-A)
F99 = A*(N**2 - 1)/(N*(N - A)) * qf(0.99, A, N-A) 
plot(1:length(miT2), miT2, type = "l", ylab = "T2",
     main = "PLS: T2-Hotelling jugadores (iteración 0)", xlab = "Jugadores")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)

# SCR
myT = mypls_j@scoreMN
myP = mypls_j@loadingMN
myE = scale(X_train_j) - myT%*%t(myP) 
mySCR = rowSums(myE^2)   # SPE 
plot(1:length(mySCR), mySCR, type = "l", main = "PLS: SCR jugadores (iteración 0)", 
     ylab = "d", xlab = "Jugadores")
g = var(mySCR)/(2*mean(mySCR))
h = (2*mean(mySCR)^2)/var(mySCR)
chi2lim = g*qchisq(0.95, df = h)
abline(h = chi2lim, col = "orange", lty = 2, lwd = 2)
abline(h = g*qchisq(0.99, df = h), col = "red3", lty = 2, lwd = 2)
#which(mySCR > 2*g*qchisq(0.99, df = h))
```


```{r, include=FALSE}
X_train_j = X_train_j[-which(mySCR > 2*g*qchisq(0.99, df = h)),] 
Y_train_j = Y_train_j[-which(mySCR > 2*g*qchisq(0.99, df = h)),] 
```

```{r, include=FALSE}
mypls_j = opls(x = X_train_j, y = as.matrix(Y_train_j), predI = 10, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")
```

```{r, echo=FALSE}
# Hotelling
misScores = mypls_j@scoreMN
varT = apply(misScores, 2, var)
miT2 = colSums(t(misScores**2) / varT)
N = nrow(X_train_j)
A = 10
F95 = A*(N**2 - 1)/(N*(N - A)) * qf(0.95, A, N-A)
F99 = A*(N**2 - 1)/(N*(N - A)) * qf(0.99, A, N-A) 
plot(1:length(miT2), miT2, type = "l", ylab = "T2",
     main = "PLS: T2-Hotelling jugadores (iteración 1)", xlab = "Jugadores")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)

# SCR
myT = mypls_j@scoreMN
myP = mypls_j@loadingMN
myE = scale(X_train_j) - myT%*%t(myP) 
mySCR = rowSums(myE^2)   # SPE 
plot(1:length(mySCR), mySCR, type = "l", main = "PLS: SCR jugadores (iteración 1)", 
     ylab = "d", xlab = "Jugadores")
g = var(mySCR)/(2*mean(mySCR))
h = (2*mean(mySCR)^2)/var(mySCR)
chi2lim = g*qchisq(0.95, df = h)
abline(h = chi2lim, col = "orange", lty = 2, lwd = 2)
abline(h = g*qchisq(0.99, df = h), col = "red3", lty = 2, lwd = 2)
#which(mySCR > 2*g*qchisq(0.99, df = h))
```

```{r, include=FALSE}
X_train_j = X_train_j[-which(miT2 > 2*F99),] 
Y_train_j = Y_train_j[-which(miT2 > 2*F99),] 
```

```{r, include=FALSE}
mypls_j = opls(x = X_train_j, y = as.matrix(Y_train_j), predI = 10, crossvalI = 10, scaleC = "standard", fig.pdfC = "none")
```

```{r, echo=FALSE}
# Hotelling
misScores = mypls_j@scoreMN
varT = apply(misScores, 2, var)
miT2 = colSums(t(misScores**2) / varT)
N = nrow(X_train_j)
A = 10
F95 = A*(N**2 - 1)/(N*(N - A)) * qf(0.95, A, N-A)
F99 = A*(N**2 - 1)/(N*(N - A)) * qf(0.99, A, N-A) 
plot(1:length(miT2), miT2, type = "l", ylab = "T2",
     main = "PLS: T2-Hotelling jugadores", xlab = "Jugadores")
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)

# SCR
myT = mypls_j@scoreMN
myP = mypls_j@loadingMN
myE = scale(X_train_j) - myT%*%t(myP) 
mySCR = rowSums(myE^2)   # SPE 
plot(1:length(mySCR), mySCR, type = "l", main = "PLS: SCR jugadores", 
     ylab = "d", xlab = "Jugadores")
g = var(mySCR)/(2*mean(mySCR))
h = (2*mean(mySCR)^2)/var(mySCR)
chi2lim = g*qchisq(0.95, df = h)
abline(h = chi2lim, col = "orange", lty = 2, lwd = 2)
abline(h = g*qchisq(0.99, df = h), col = "red3", lty = 2, lwd = 2)
#which(mySCR > 2*g*qchisq(0.99, df = h))
```

Tras haber eliminado 4 jugadores en dos iteraciones de reajustes del modelo, vemos que hay pocos jugadores que pasen el límite del 95%-99%. Por encima del límite de confianza de 95% tenemos `r nrow(as.matrix(which(miT2 > F95)))` observaciones y por encima del límite de 99% tenemos `r nrow(as.matrix(which(miT2 > F99)))` observaciones, que respectivamente son el `r round(nrow(as.matrix(which(miT2 > F95)))/11943, 3)`% y el `r round(nrow(as.matrix(which(miT2 > F99)))/11943, 3)`%

Respecto a la suma de cuadrados residual, `r round(nrow(as.matrix(which(mySCR > g*qchisq(0.95, df = h))))/11943, 3)`%, `r round(nrow(as.matrix(which(mySCR > g*qchisq(0.99, df = h))))/11943, 3)`%

en este caso tampoco encontramos una gran cantidad de jugadores que sobrepasen el límite, y aquellos que lo pasan son los importantes, por lo que tampoco podemos eliminarlos.


### Relación lineal entre scores Jugadores

Por otro lado, si observamos en este caso la relación entre los scores de los jugadores, vemos que hay una tendencia lineal donde se encuentran la mayoría de jugadores, que se acaba convirtiendo en la primera componente exponencial, donde no hay casi valores. Esta exponencialidad puede ser debida a los jugadores "anómalos" que son los importantes. Para el resto de componentes la relación lineal ajusta prácticamente el modelo.

Cabe destacar, de nuevo, que esto podría arreglarse mediante el uso de transformaciones en los datos como hemos explicado en el caso de los porteros, pero es una tarea muy compleja que podrá ser desarrollada en un futuro.


```{r, fig.width=19.5, fig.height=8, echo=FALSE}
# t vs u
par(mfrow = c(2,5))
plot(mypls_j@scoreMN[,1], mypls_j@uMN[,1], xlab = "t", ylab = "u",
     main = "Componente 1", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_j@scoreMN[,2], mypls_j@uMN[,2], xlab = "t", ylab = "u",
     main = "Componente 2", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_j@scoreMN[,3], mypls_j@uMN[,3], xlab = "t", ylab = "u",
     main = "Componente 3", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_j@scoreMN[,4], mypls_j@uMN[,4], xlab = "t", ylab = "u",
     main = "Componente 4", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_j@scoreMN[,5], mypls_j@uMN[,5], xlab = "t", ylab = "u",
     main = "Componente 5", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_j@scoreMN[,6], mypls_j@uMN[,6], xlab = "t", ylab = "u",
     main = "Componente 6", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_j@scoreMN[,7], mypls_j@uMN[,7], xlab = "t", ylab = "u",
     main = "Componente 7", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_j@scoreMN[,8], mypls_j@uMN[,8], xlab = "t", ylab = "u",
     main = "Componente 8", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_j@scoreMN[,9], mypls_j@uMN[,9], xlab = "t", ylab = "u",
     main = "Componente 9", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)
plot(mypls_j@scoreMN[,10], mypls_j@uMN[,10], xlab = "t", ylab = "u",
     main = "Componente 10", col = "red3")
abline(a=0, b=1, col = "grey", lty = 3)

diag(cor(mypls_j@scoreMN, mypls_j@uMN))
```


### Interpretación del modelo PLS Jugadores

Los siguientes gráficos nos servirán para interpretar el modelo PLS.

```{r, echo = FALSE, fig.width=19.5, fig.height=4}
par(mfrow = c(1,5))
plot(x = mypls_j, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(1:2), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)
plot(x = mypls_j, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(3:4), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)
plot(x = mypls_j, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(5:6), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)
plot(x = mypls_j, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(7:8), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)
plot(x = mypls_j, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(9:10), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)
```


```{r, echo=FALSE, fig.width=19.5, fig.height=4}
par(mfrow = c(1,5))
plot(x = mypls_j, typeVc = "xy-weight",
     parCexN = 0.8, parCompVi = c(1:2), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)

plot(x = mypls_j, typeVc = "xy-weight",
     parCexN = 0.8, parCompVi = c(3:4), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)

plot(x = mypls_j, typeVc = "xy-weight",
     parCexN = 0.8, parCompVi = c(5:6), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)

plot(x = mypls_j, typeVc = "xy-weight",
     parCexN = 0.8, parCompVi = c(7:8), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)

plot(x = mypls_j, typeVc = "xy-weight",
     parCexN = 0.8, parCompVi = c(9:10), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)

```

### Predicciones con PLS Jugadores

Antes de predecir con la muestra de test final, realizamos una primera predicción para ver cómo funciona nuestro modelo. Observamos cómo el modelo se ajusta en un principio a los datos pero al final acaba desviándose.

```{r pred1b, fig.width=12, fig.height=8, echo=FALSE}
# Observados versus predichos
Ypred = predict(mypls_j)
Ypred[,3]=round(Ypred[,3])

par (mfrow = c(2,3))
for (i in 1:ncol(Y_train_j)) {
  plot(Y_train_j[,i], Ypred[,i], asp = 1, main = colnames(Y_train_j)[i],
     xlab = "observado", ylab = "predicho")
abline(a=0, b=1, col = "red3", lwd = 2, lty = 2)
}
```


### Predicciones para test jugadores

Finalmente, realizamos las predicciones con nuestros datos de test. Como habíamos observado antes, el modelo consigue ajustar en un principio a los datos, pero luego se desvía infravalorando bastante a los jugadores con valores altos, igual que hemos visto en el caso de los porteros. Como dijimos anteriormente, esto puede ser debido a que el modelo se ajusta bastante a la mayoría, que son los jugadores mediocres, no consiguiendo bien predecir el valor de los jugadores importantes, que son menos.

```{r, fig.width=12, fig.height=8, echo=FALSE}
Ypred = predict(mypls_j, X_test_j)
Ypred[,3]=round(Ypred[,3])
# Observados versus predichos
par (mfrow = c(2,3))
for (i in 1:ncol(Y_test_j)) {
  plot(Y_test_j[,i], Ypred[,i], asp = 1, main = colnames(Y_test_j)[i],
     xlab = "observado", ylab = "predicho")
abline(a=0, b=1, col = "red3", lwd = 2, lty = 2)
}
```



# Anexo 0
## Pre-procesado de los datos
```{r importar datos2}
datos = read.csv("FIFA.csv", encoding = 'UTF-8', na.strings=c("","na"))
#Los datos faltantes estaban escritos como espacios en blanco, por lo que los sustituimos por NA para tratarlos con mayor facilidad
```

## Eliminación de variables inútiles

Eliminaremos las variables que no serán utilizadas en el análisis. 

```{r borrar variables2}
fifa = datos[,-c(1,2,3,5,7,11,14,19:21,23:26,29:54,89)]
fifa_paralelo = datos[,-c(1,2,5,7,11,14,19:21,23:26,29:54,89)]
```


## Tratamiento de datos faltantes

Para el tratamiento de datos faltantes, realizamos una primera exploración de los datos. Obtenemos el porcentaje de datos faltates existente en cada columna y observamos una baja cantidad de datos faltantes. Respecto al numero de datos faltantes, hay 241 jugadores con valor faltante en la variable Club y 60 jugadores con valor faltante en la variable Posición. Como vemos en los porcentajes, el 0,26% de los jugadores de la base de datos no tienen valores sobre las variables de habilidades. Al tratarse de un grupo tan reducido, decidimos eliminarlos directamente. 

Véase a continuación el porcentaje de valores faltantes para cada variable:

```{r variables faltantes2, warning=FALSE}

vis_miss(fifa, warn_large_data =  FALSE)
sum(is.na(fifa))
#gg_miss_upset(fifa)
#gg_miss_upset(fifa, nsets = n_var_miss(fifa))
#gg_miss_upset(fifa, 
 #             nsets = n_var_miss(fifa),
  #            nintersects = NA)
#gg_miss_var(fifa)

fifa <- na.omit(fifa)  #eliminar los faltantes
```


## Limpieza y asignación de los tipos de variables adecuados

Hay variables que no están en su clase correspondiente, y algunas que hay que modificar para facilitar su tratamiento. 
Eliminamos simbolo € de las variables Wage y Value, las transformamos a tipo numerico y pasamos a numerico el peso y la altura también.

```{r transformacion de precio y valor2}

#Eliminamos el simbolo de € de la variable value
fifa$Value = gsub("^\\€", "", fifa$Value)

#Eliminamos el simbolo de € de la variable wage
fifa$Wage = gsub("^\\€", "", fifa$Wage)

#Transformamos el texto en número de acuerdo a si es M€, K€ o €.
numeric_value = function(char){
      num = as.numeric(substring(char, 1, nchar(char)-1))
      k = substring(char,nchar(char),nchar(char))
      mult = 1
      if(k=='M'){mult = 1000000}
      if(k=='K'){mult = 1000}
      num*mult
}
fifa$Value = sapply(fifa$Value, numeric_value)
fifa$Wage = sapply(fifa$Wage, numeric_value)

#La variable de la altura del jugador está medida en pies más pulgadas. La transformamos a valor numérico expresado en cms.

fifa$Height = as.numeric(gsub("\'\\w+$", "", fifa$Height))*30.48 +
      as.numeric(gsub("^\\w+'", "", fifa$Height))*2.54

#La variable Weight representa el peso del jugador en libras. La transformamos a valor numérico expresado en kgs.

fifa$Weight = as.numeric(gsub("lbs$", "", fifa$Weight))*0.453592



#La variable Preferred.Foot se pasa a tipo binario.

library(fastDummies)
fifa = dummy_cols(fifa, select_columns = 'Preferred.Foot', remove_selected_columns = TRUE)
```


La variable Position se recodifica. Tiene 27 valores diferentes y vamos a convertirlos en ocho (portero, lateral, central, medio, medio ofensivo, medio defensivo, extremo y delantero), agrupándolos por las categorías más importantes para facilitar la interpretación de las variables. Después se convierte a binario.
```{r}
for (i in 1:nrow(fifa)){
  if(fifa$Position[i] %in% c('CF', 'ST', 'RF', 'LF', 'LS', 'RS')){fifa$Position[i]='DEL'}
  if(fifa$Position[i] %in% c('RW', 'LW')){fifa$Position[i]='EXT'}
  if(fifa$Position[i] %in% c('LM', 'CM', 'LCM', 'RM', 'RCM')){fifa$Position[i]='MED'}
  if(fifa$Position[i] %in% c('LAM', 'CAM', 'RAM')){fifa$Position[i]='MEDOF'}
  if(fifa$Position[i] %in% c('LDM', 'CDM', 'RDM')){fifa$Position[i]='MEDDEF'}
  if(fifa$Position[i] %in% c('LCB', 'CB', 'RCB')){fifa$Position[i]='CEN'}
  if(fifa$Position[i] %in% c('LWB', 'LB', 'RB', 'RWB')){fifa$Position[i]='LAT'}
  if(fifa$Position[i] %in% c('GK')){fifa$Position[i]='POR'}
}


fifa = dummy_cols(fifa, select_columns = 'Position', remove_selected_columns = FALSE)

#table(fifa$Position)
```

Creamos dataframe con el tipo de cada variable para facilitar la implementación de los métodos más adelante.

```{r}
descFifa = data.frame("variable" = colnames(fifa),
                      "tipo" = c("numerical", "categorical",
                                 rep("numerical", 2), "categorical", 
                                 rep("numerical", 5), "categorical",
                                 rep("numerical", 46)), stringsAsFactors = FALSE)
rownames(descFifa) = descFifa$variable
```


## Análisis exploratorio

A continuación, haremos un conciso análisis exploratorio de nuestras variables para ir familiarizándonos con ellas. Estudiamos las distribuciones de cada variable para encontrar posibles datos anómalos y para decidir si será necesario estandarizar todas las variables numéricas de cara a la implementación del PCA más adelante.

```{r}
summary(fifa[,descFifa$variable[descFifa$tipo == "numerical"]])

table(fifa$Position)
table(fifa$International.Reputation)
table(fifa$Weak.Foot)
table(fifa$Skill.Moves)
```

### Variables de habilidades de jugador

En el siguiente gráfico tenemos una serie de boxplots de las variables de habilidades de los jugadores, todas ellas medidas en una misma escala de 0 a 100. Podemos ver una clara diferenciación entre todas la variables menos las cinco últimas de la derecha. La diferencia de este pequeño grupo de variables se debe a que son medidas pensadas para los porteros, por lo que todos los demás jugadores que no lo sean tendrán valores bajos en dichas variables. 

En general, suponemos (sería lógico) que la gran mayoría de los datos atípicos que aparecen en cada boxplot son los porteros.

```{r primeros boxplots2, fig.width=15, fig.height=7}
fifa_numericas = fifa[,setdiff(colnames(fifa), c("Nationality", "Club"))]

fifa_stats = fifa_numericas[,setdiff(colnames(fifa_numericas), c("Preferred.Foot_Right", "Preferred.Foot_Left", "Age", "Wage", "Value",
                                                                 "International.Reputation", "Skill.Moves", "Height", "Weight", "Weak.Foot",
                                                                 "Overall", "Potential","Position_DEL","Position_POR","Position_MED","Position_LAT",
                                                                 "Position_MEDDEF","Position_MEDOF","Position_EXT","Position_CEN","Position"))]


par(mar = c(9,4,2,2))
boxplot(fifa_stats, las = 2)

```

Pero, como sabemos, estas no son las únicas variables que se considerarán en el estudio. Tenemos otras más de tipo numérico, pero no están medidas de la misma forma que las mostradas en el gráfico anterior. 

Realizamos unos histogramas del resto de variables que no corresponden a stats de los jugadores. Saltan a la vista las variables Value, Wage, International Reputation, cuentan con una fuerte asímetría positiva, es bastante seguro que tengamos que eliminar bastantes valores debido a esto. La variable Edad también es parecida en este sentido, pero no tanto como las anteriores. Por las demás, muestran una distribución normal.

```{r histogramas no stats2, warning=FALSE}
#par(mfrow = c(1, 3))

hist1 = pl <- ggplot(fifa, aes(x=Age))
hist1 = pl + geom_histogram(bins=30)
hist2 = pl <- ggplot(fifa, aes(x=Value))
hist2 = pl + geom_histogram(bins=30)
hist3 = pl <- ggplot(fifa, aes(x=Wage))
hist3 = pl + geom_histogram(bins=30)
hist4 = pl <- ggplot(fifa, aes(x=Height))
hist4 = pl + geom_histogram(bins=30)
hist5 = pl <- ggplot(fifa, aes(x=Weight))
hist5 = pl + geom_histogram(bins=30)
hist6 = pl <- ggplot(fifa, aes(x=Overall))
hist6 = pl + geom_histogram(bins=30)
hist7 = pl <- ggplot(fifa, aes(x=International.Reputation))
hist7 = pl + geom_histogram(bins=30)
hist8 = pl <- ggplot(fifa, aes(x=Weak.Foot))
hist8 = pl + geom_histogram(bins=30)
hist9 = pl <- ggplot(fifa, aes(x=Skill.Moves))
hist9 = pl + geom_histogram(bins=30)

ggarrange(hist1,hist2,hist3,hist4,hist5,hist6,hist7,hist8,hist9)
#par(mfrow = c(1, 1))
```


Véase ahora un gráfico de boxplots similar al primero, pero con todo el conjunto de variables. Claramente necesitaremos tipificar todas las variables para una posible comparación. 

```{r segundos boxplots2,fig.width=18, fig.height=7}
fifa_numericas = fifa[,setdiff(colnames(fifa), c("Nationality", "Club", "Position", "Preferred.Foot_Right", "Preferred.Foot_Left"))]

par(mar = c(9,4,2,2))
boxplot(fifa_numericas, las = 2)

```

### Conclusión - Centrado y escalado

Ya con los datos centrados y escalados mediante varianza unitaria, repetimos el gráfico. Tal y como sospechábamos antes, Value y Wage tienen una gran cantidad de valores fuertemente anómalos. Esto nos lleva a preguntarnos si deberíamos excluir estas variables para a la hora de hacer nuestros dos primeros métodos en este trabajo: PCA y clustering. Intentaremos hacer el análisis PCA incluyéndolas e intentando tratar valores que salgan muy anómalos, si es que lo hacen.

```{r terceros boxplots2, fig.width=18, fig.height=7}
fifa_numericas = fifa[,setdiff(colnames(fifa), c("Nationality", "Club", "Position", "Preferred.Foot_Right", "Preferred.Foot_Left"))]

fifa_numericas <- scale(fifa_numericas, center = T, scale = T) 
par(mar = c(9,4,2,2))
boxplot(fifa_numericas, las = 2)

```

#Anexo 1
##Clustering con los datos originales. 

```{r euclidean distance from origibnal dataset}
#fifa_numericas_or = round(fifa_numericas, digits = 3)
#fifa_numericas_or = as.data.frame(fifa_numericas_or)

#fifa_numericas_jugadores = subset(fifa_numericas_or, Position_POR != 2.827) 

#midist_or = get_dist(fifa_numericas_jugadores, stand=FALSE, method = "euclidean")
```

```{r}
#fviz_nbclust(x = fifa_numericas_jugadores, FUNcluster = kmeans, method = "silhouette", 
#             k.max = 10, verbose = FALSE) +
#  labs(title = "K-means")

#par(mfrow=c(1,1))
```

Se obtiene un coeficiente de silhouette bastante bajo, y indica que el óptimo es 9 clusters. 

```{r cluster final k-means}
#clust_means_1_or <- kmeans(fifa_numericas_jugadores, centers = 7, nstart = 20)
#clust_means_2_or <- kmeans(fifa_numericas_jugadores, centers = 9, nstart = 20)
#set.seed(100)
```

```{r cluster final k-medoides}
#clust_medoides_1_or <- clara(fifa_numericas_jugadores, 7, metric = "euclidean", stand = FALSE, samples = 50, pamLike = TRUE)
#clust_medoides_2_or <- clara(fifa_numericas_jugadores, 9, metric = "euclidean", stand = FALSE, samples = 50, pamLike = TRUE)
```

```{r comparacion}
#par(mfrow = c(1,3))
#plot(silhouette(clust_means_1_or$cluster, midist_or), col=rainbow(7), border=NA, main = "K-MEDIAS")
#plot(silhouette(clust_means_2_or$cluster, midist_or), col=rainbow(9), border=NA, main = "K-MEDIAS")
```

```{r}
#par(mfrow=c(1,3))
#plot(silhouette(clust_medoides_1_or$clustering, midist_or), col=rainbow(7), border=NA, main = "K-MEDOIDES")
#plot(silhouette(clust_medoides_2_or$clustering, midist_or), col=rainbow(9), border=NA, main = "K-MEDOIDES")

```

```{r}
#clust_or = factor(clust_means_2_or$cluster)
#set.seed(100)
```

```{r}
#par(mfrow=c(1,3))

#fviz_pca_ind(res.pca_jugadores, geom = "point", habillage = clust_or, addEllipses = FALSE,
#             palette = c("#999999", "#E69F00", "#56B4E9", "#FF0000", "#FFFF00", "#800000", "#008080", "#FF00FF", "#000080"), axes = #c(1,2))

#fviz_pca_var(res.pca_jugadores, axes = c(1,2), repel = TRUE, col.var = "contrib", 
#             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup","quali"),select.var = list(name = #c("Position_CEN","Position_DEL","Position_MEDOF","Position_MEDDEF","Position_EXT","Position_LAT","Position_MED"))) #, select.var = list(contrib = 70) 

#fviz_pca_var(res.pca_jugadores, axes = c(1,2), repel = TRUE, col.var = "contrib",
#             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),invisible = c("quanti.sup", "quali"), select.var = list(contrib = 30) )

                                                                                                                   
```

Seguiremos el análisis clustering con las componentes principales en lugar de los datos originales, debido a que no se pueden obtener conclusiones de estos, los clusters se solapan demasiado. 

##Perfil medio de los clusters.

```{r include=FALSE}
#df_jugadores_after_PCA = as.data.frame(res.pca_jugadores$ind$coord)#
#midist_jugadores = get_dist(df_jugadores_after_PCA, stand=FALSE, method = "euclidean")
```



```{r include=FALSE}
#solo admite la distancia euclidea. 

#fviz_nbclust(x = df_jugadores_after_PCA, FUNcluster = kmeans, method = "silhouette", 
#             k.max = 10, verbose = FALSE) +
#  labs(title = "K-means sin porteros")

#par(mfrow=c(1,1))
```




```{r include=FALSE}
#fviz_nbclust(x = df_jugadores_after_PCA, FUNcluster = cluster::pam, method = "silhouette", 
#             k.max = 10, verbose = FALSE) +
#  labs(title = "Num. clusters")
```




```{r include=FALSE}
#clust_means_1 <- kmeans(df_jugadores_after_PCA, centers = 2, nstart = 20)
#clust_means_2 <- kmeans(df_jugadores_after_PCA, centers = 3, nstart = 20)
#clust_means_3 <- kmeans(df_jugadores_after_PCA, centers = 5, nstart = 20)
#set.seed(100)
```

```{r  include=FALSE}
#clust_medoides_1 <- clara(df_jugadores_after_PCA, 2, metric = "euclidean", stand = FALSE, samples = 50, pamLike = TRUE)
#clust_medoides_2 <- clara(df_jugadores_after_PCA, 3, metric = "euclidean", stand = FALSE, samples = 50, pamLike = TRUE)
#clust_medoides_3 <- clara(df_jugadores_after_PCA, 5, metric = "euclidean", stand = FALSE, samples = 50, pamLike = TRUE)
```

```{r  include=FALSE}
#par(mfrow = c(1,3))
#plot(silhouette(clust_means_1$cluster, midist_jugadores), col=rainbow(2), border=NA, main = "kmeans")
#plot(silhouette(clust_means_2$cluster, midist_jugadores), col=rainbow(3), border=NA, main = "kmeans")
#plot(silhouette(clust_means_3$cluster, midist_jugadores), col=rainbow(5), border=NA, main = "kmeans")
```

```{r include=FALSE}
#par(mfrow=c(1,3))
#plot(silhouette(clust_medoides_1$clustering, midist_jugadores), col=rainbow(2), border=NA, main = "kmedoides")
#plot(silhouette(clust_medoides_2$clustering, midist_jugadores), col=rainbow(3), border=NA, main = "kmedoides")
#plot(silhouette(clust_medoides_3$clustering, midist_jugadores), col=rainbow(5), border=NA, main = "kmedoides")

```



```{r include=FALSE}
#clust = factor(clust_means_3$cluster)
#set.seed(100)
```


```{r include=FALSE, warning=FALSE}
#par(mfrow=c(1,3))

#fviz_pca_ind(res.pca_jugadores, geom = "point", habillage = clust, addEllipses = FALSE,
#             palette = rainbow(5), axes = c(1,2))

#fviz_pca_var(res.pca_jugadores, axes = c(1,2), repel = TRUE, col.var = "contrib", 
#             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup","quali"),select.var = list(name = #c("Position_CEN","Position_DEL","Position_MEDOF","Position_MEDDEF","Position_EXT","Position_LAT","Position_MED"))) #, select.var = #list(contrib = 70) 

#fviz_pca_var(res.pca_jugadores, axes = c(1,2), repel = TRUE, col.var = "contrib",
#             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),invisible = c("quanti.sup", "quali"), select.var = list(contrib = 30) )
                                                                                                                   
```

```{r include=FALSE, warning=FALSE}
#par(mfrow=c(1,3))

#fviz_pca_ind(res.pca_jugadores, geom = "point", habillage = clust, addEllipses = FALSE,
#             palette = rainbow(5), axes = c(3,4))

#fviz_pca_var(res.pca_jugadores, axes = c(3,4), repel = TRUE, col.var = "contrib", 
#             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup","quali"),select.var = list(name = #c("Position_CEN","Position_DEL","Position_MEDOF","Position_MEDDEF","Position_EXT","Position_LAT","Position_MED"))) #, select.var = #list(contrib = 70) 

#fviz_pca_var(res.pca_jugadores, axes = c(3,4), repel = TRUE, col.var = "contrib",
#             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),invisible = c("quanti.sup", "quali"), select.var = list(contrib = 30) )
                                                                                                                   


#set.seed(100)
```




```{r}
#par(mfrow=c(1,3))

#fviz_pca_ind(res.pca_jugadores, geom = "point", habillage = clust, addEllipses = FALSE,
#             palette = rainbow(5), axes = c(5,6))

#fviz_pca_var(res.pca_jugadores, axes = c(5,6), repel = TRUE, col.var = "contrib", 
#             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), invisible = c("quanti.sup","quali"),select.var = list(name = #c("Position_CEN","Position_DEL","Position_MEDOF","Position_MEDDEF","Position_EXT","Position_LAT","Position_MED"))) #, select.var = #list(contrib = 70) 

#fviz_pca_var(res.pca_jugadores, axes = c(5,6), repel = TRUE, col.var = "contrib",
#             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),invisible = c("quanti.sup", "quali"), select.var = list(contrib = 30) )
                                                                                                                   
```
En las dimensiones 5 y 6, la variabilidad esta explicada principalmente por las variables "Preferred.Foot.Left", y "Preferred.Foot.Right". Por tanto, al no tratarse de variables relacionadas con las habilidades de juego no nos interesan para el análisis. 


```{r}
#mediasCluster = aggregate(df_jugadores_after_PCA, by = list("cluster" = clust), mean)[,-1]
#rownames(mediasCluster) = paste0("c",1:5)
#kable(t(round(mediasCluster,2)))
```

```{r}
#matplot(t(mediasCluster), type = "l", col = rainbow(5), ylab = "", xlab = "", lwd = 2,
#       lty = 1, main = "Perfil medio de los clusters", xaxt = "n")
#axis(side = 1, at = 1:ncol(df_after_PCA), labels = colnames(df_after_PCA), las = 2)
#legend("topleft", as.character(1:5), col = rainbow(5), lwd = 2, ncol = 3, bty = "n")
```
Podemos observar como en las componentes 5 y 6 el valor de cada cluster es muy bajo, por lo que estas dimensiones no contribuyen demasiado a la separación entre grupos. 



